{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76e6c720",
   "metadata": {},
   "source": [
    "# Lidar Products Generation Notebook\n",
    "\n",
    "## Overview\n",
    "This notebook processes USGS 3DEP (3D Elevation Program) LiDAR data to generate high-resolution elevation products for meadow assessment. The workflow downloads, filters, and processes point cloud data to create Digital Terrain Models (DTM), Digital Surface Models (DSM), and Canopy Height Models (CHM) at 0.6-meter resolution.\n",
    "\n",
    "## Methodology\n",
    "The processing pipeline includes:\n",
    "1. **Data Discovery**: Query USGS 3DEP catalog for intersecting LiDAR datasets\n",
    "2. **Point Cloud Processing**: Download and filter LiDAR points using PDAL\n",
    "3. **Surface Generation**: Create DTM (bare earth) and DSM (first surface) models\n",
    "4. **Gap Filling**: Use Inverse Distance Weighting (IDW) to fill data gaps\n",
    "5. **Clipping**: Extract products within the meadow boundary\n",
    "6. **Canopy Analysis**: Generate CHM for vegetation height assessment\n",
    "\n",
    "## Data Products\n",
    "- **DTM (Digital Terrain Model)**: Bare earth elevation (ground surface)\n",
    "- **DSM (Digital Surface Model)**: First surface elevation (includes vegetation/structures)\n",
    "- **CHM (Canopy Height Model)**: Vegetation height (DSM - DTM)\n",
    "\n",
    "## Requirements\n",
    "- Meadow boundary polygon (`meadow_extent.geojson`)\n",
    "- Internet connection for USGS 3DEP data access\n",
    "- PDAL library for point cloud processing\n",
    "\n",
    "## Processing Parameters\n",
    "- **Resolution**: 0.6 meters\n",
    "- **Coordinate System**: NAD83(2011) / Colorado Central (EPSG:6339)\n",
    "- **Point Classification**: Filters noise and retains ground/vegetation points\n",
    "- **Gap Filling**: IDW interpolation within meadow boundaries only\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f55c5c5",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "Configure Python environment and import required libraries for LiDAR processing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98fd3df",
   "metadata": {},
   "source": [
    "### Library Imports\n",
    "Import all required libraries for geospatial processing, point cloud analysis, and data visualization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753ce44d",
   "metadata": {},
   "source": [
    "## Study Site Configuration\n",
    "Set the study area name and configure file paths for processing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b545281b",
   "metadata": {},
   "source": [
    "## USGS 3DEP Dataset Discovery\n",
    "Query the USGS 3D Elevation Program catalog to find LiDAR datasets that intersect with the study area."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00603bc",
   "metadata": {},
   "source": [
    "## PDAL Pipeline Construction\n",
    "Create a processing pipeline for downloading and filtering LiDAR point cloud data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed366fe",
   "metadata": {},
   "source": [
    "## Point Cloud Processing Execution\n",
    "Execute the PDAL pipeline to download, filter, and process LiDAR data. This may take several minutes depending on the dataset size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3164d4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add parent directory to Python path to access custom modules\n",
    "import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f9d68e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raster processing and coordinate transformation\n",
    "from rasterio.warp import calculate_default_transform, reproject, Resampling\n",
    "import rasterio as rio\n",
    "\n",
    "# Geospatial libraries\n",
    "from shapely import BufferCapStyle, BufferJoinStyle, buffer\n",
    "from shapely.geometry import shape, Point, Polygon\n",
    "from shapely.ops import transform\n",
    "from osgeo import gdal\n",
    "import geopandas as gpd\n",
    "\n",
    "# Point cloud processing\n",
    "import pdal\n",
    "\n",
    "# Data manipulation and analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualization and UI\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "\n",
    "# File system and web requests\n",
    "from pathlib import Path\n",
    "import requests\n",
    "import json\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Custom LiDAR processing functions\n",
    "import src.lidar_products as lp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20233b61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing lidar data for: Lacey meadow\n"
     ]
    }
   ],
   "source": [
    "# Study area identifier - change this to match your meadow site\n",
    "# Available options: \"Lacey\", \"Humbug\", \"subb\"\n",
    "name = \"Lacey\"\n",
    "#name = \"Humbug\" \n",
    "#name = \"subb\"\n",
    "\n",
    "print(f\"Processing lidar data for: {name} meadow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e86f668a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working directory set to: /media/grendel/7db216a7-836f-4e8d-b439-e4f999cedb23/USGS/meadow_assessment/data/Lacey\n",
      "Output files will be saved to: /media/grendel/7db216a7-836f-4e8d-b439-e4f999cedb23/USGS/meadow_assessment/data/Lacey/../data/Lacey\n"
     ]
    }
   ],
   "source": [
    "# Create output directory for the selected study site\n",
    "# All LiDAR products will be saved to ../data/{name}/\n",
    "OUTPUT_DIR = Path(f\"../data/{name}\")\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Change working directory to the output folder\n",
    "os.chdir(OUTPUT_DIR)\n",
    "print(f\"Working directory set to: {os.getcwd()}\")\n",
    "print(f\"Output files will be saved to: {OUTPUT_DIR.absolute()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8dff47b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Found meadow boundary file: meadow_extent.geojson\n"
     ]
    }
   ],
   "source": [
    "# Define the meadow boundary file path\n",
    "# This GeoJSON file must exist in the meadow folder and defines the area of interest\n",
    "shapefile_path = \"meadow_extent.geojson\"\n",
    "\n",
    "# Verify the boundary file exists\n",
    "if os.path.exists(shapefile_path):\n",
    "    print(f\"âœ“ Found meadow boundary file: {shapefile_path}\")\n",
    "else:\n",
    "    print(f\"âœ— ERROR: Meadow boundary file not found at {shapefile_path}\")\n",
    "    print(\"Please ensure meadow_extent.geojson exists in the data folder.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f2be85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for intersecting USGS 3DEP LiDAR datasets...\n",
      "Vector file loaded.\n",
      "resources.geojson exists in the data folder.\n",
      "3DEP polygons loaded and projected to Web Mercator (EPSG:3857)\n",
      "AOI buffered by 10 meters\n",
      "[('USGS_LPC_CA_NoCAL_Wildfires_B1_2018', <MULTIPOLYGON (((-120.174 38.833, -120.116 38.863, -120.116 38.972, -120.134...>, <MULTIPOLYGON (((-13377749 4697773.7, -13371249 4702103.8, -13371249 4717692...>, 'https://s3-us-west-2.amazonaws.com/usgs-lidar-public/USGS_LPC_CA_NoCAL_Wildfires_B1_2018/ept.json', np.int64(86376910091))]\n",
      "Found 1 intersecting dataset(s)\n",
      "3DEP polygons loaded and projected to Web Mercator (EPSG:3857)\n",
      "AOI buffered by 10 meters\n",
      "[('USGS_LPC_CA_NoCAL_Wildfires_B1_2018', <MULTIPOLYGON (((-120.174 38.833, -120.116 38.863, -120.116 38.972, -120.134...>, <MULTIPOLYGON (((-13377749 4697773.7, -13371249 4702103.8, -13371249 4717692...>, 'https://s3-us-west-2.amazonaws.com/usgs-lidar-public/USGS_LPC_CA_NoCAL_Wildfires_B1_2018/ept.json', np.int64(86376910091))]\n",
      "Found 1 intersecting dataset(s)\n"
     ]
    }
   ],
   "source": [
    "# Discover USGS 3DEP datasets that intersect with the meadow boundary\n",
    "# This function:\n",
    "# 1. Downloads the 3DEP catalog if not present locally\n",
    "# 2. Projects the meadow boundary to Web Mercator (EPSG:3857) \n",
    "# 3. Buffers the boundary by 10m to ensure complete coverage\n",
    "# 4. Finds all intersecting LiDAR datasets\n",
    "print(\"Searching for intersecting USGS 3DEP LiDAR datasets...\")\n",
    "intersecting_polys, AOI_EPSG3857_wkt = lp.usgs_3dep_datasets(shapefile_path)\n",
    "#print(f\"Found {len(intersecting_polys)} intersecting dataset(s)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91c5cb80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available LiDAR datasets:\n",
      "  1. USGS_LPC_CA_NoCAL_Wildfires_B1_2018 (86,376,910,091 points estimated)\n",
      "\n",
      "Total datasets to process: 1\n"
     ]
    }
   ],
   "source": [
    "# Extract dataset names for PDAL pipeline construction\n",
    "usgs_3dep_datasets = []\n",
    "\n",
    "print(\"Available LiDAR datasets:\")\n",
    "for i, poly in enumerate(intersecting_polys):\n",
    "    dataset_name = poly[0]\n",
    "    point_count = poly[4]\n",
    "    usgs_3dep_datasets.append(dataset_name)\n",
    "    print(f\"  {i+1}. {dataset_name} ({point_count:,} points estimated)\")\n",
    "\n",
    "print(f\"\\nTotal datasets to process: {len(usgs_3dep_datasets)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f916741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constructing PDAL processing pipeline...\n",
      "âœ“ Pipeline configured with filtering and raster generation stages\n"
     ]
    }
   ],
   "source": [
    "# Build PDAL pipeline for point cloud processing\n",
    "# The pipeline includes:\n",
    "# - Data readers for each USGS 3DEP dataset\n",
    "# - Outlier and noise filtering\n",
    "# - Point classification filtering  \n",
    "# - Coordinate system reprojection to EPSG:6339\n",
    "# - Ground point classification using Progressive Morphological Filter\n",
    "# - Raster generation (DSM and DTM) at 0.6m resolution\n",
    "print(\"Constructing PDAL processing pipeline...\")\n",
    "p_pipeline = lp.pdal_pipeline(AOI_EPSG3857_wkt, usgs_3dep_datasets)\n",
    "print(\"âœ“ Pipeline configured with filtering and raster generation stages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea7c06fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ PDAL pipeline initialized and ready for execution\n"
     ]
    }
   ],
   "source": [
    "# Initialize PDAL pipeline object\n",
    "# Convert the pipeline dictionary to JSON format for PDAL execution\n",
    "pl = pdal.Pipeline(json.dumps(p_pipeline))\n",
    "print(\"âœ“ PDAL pipeline initialized and ready for execution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "94e6bf14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting LiDAR processing...\n",
      "This may take several minutes depending on dataset size...\n",
      "âœ“ PDAL pipeline execution completed\n",
      "Generated temporary files: dtm_temp.tif, dsm_temp.tif\n",
      "CPU times: user 4min 25s, sys: 7.42 s, total: 4min 33s\n",
      "Wall time: 4min 11s\n",
      "âœ“ PDAL pipeline execution completed\n",
      "Generated temporary files: dtm_temp.tif, dsm_temp.tif\n",
      "CPU times: user 4min 25s, sys: 7.42 s, total: 4min 33s\n",
      "Wall time: 4min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Execute the PDAL pipeline\n",
    "# This will:\n",
    "# 1. Download LiDAR points from AWS S3 (USGS 3DEP)\n",
    "# 2. Apply filters to remove noise and outliers\n",
    "# 3. Classify ground points using Progressive Morphological Filter\n",
    "# 4. Generate temporary DSM and DTM rasters\n",
    "# \n",
    "# Processing time varies by dataset size:\n",
    "# - Small areas (< 10M points): 2-5 minutes\n",
    "# - Medium areas (10-30M points): 5-15 minutes  \n",
    "# - Large areas (> 30M points): 15+ minutes\n",
    "\n",
    "print(\"Starting Lidar processing...\")\n",
    "print(\"This may take several minutes depending on dataset size...\")\n",
    "\n",
    "pl.execute()\n",
    "\n",
    "print(\"âœ“ PDAL pipeline execution completed\")\n",
    "print(\"Generated temporary files: dtm_temp.tif, dsm_temp.tif\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f88a28",
   "metadata": {},
   "source": [
    "**Processing Time Reference:**\n",
    "- Lacey: 2m47s, 7,088,795 points  \n",
    "- Humbug: 15m43s, 25,865,590 points\n",
    "\n",
    "*Processing time scales roughly with point count and internet connection speed.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00cedc17",
   "metadata": {},
   "source": [
    "## Gap Filling with Inverse Distance Weighting\n",
    "Fill data gaps (NoData pixels) within the meadow boundary using spatial interpolation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52b2963",
   "metadata": {},
   "source": [
    "## Final Product Generation\n",
    "Clip rasters to the exact meadow boundary and generate the Canopy Height Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7ffb77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filling gaps in DTM using IDW interpolation...\n",
      "âœ“ Filled dtm_temp.tif and saved to dtm_temp_filled.tif\n",
      "âœ“ Filled dtm_temp.tif and saved to dtm_temp_filled.tif\n"
     ]
    }
   ],
   "source": [
    "# Fill NoData gaps in the Digital Terrain Model (DTM)\n",
    "# Uses Inverse Distance Weighting (IDW) interpolation\n",
    "# Only fills gaps within the meadow boundary to preserve data integrity\n",
    "print(\"Filling gaps in DTM using IDW interpolation...\")\n",
    "result_dtm = lp.fill_nodata('dtm_temp.tif', shapefile_path)\n",
    "#print(f\"âœ“ {result_dtm}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615c8b54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filling gaps in DSM using IDW interpolation...\n"
     ]
    }
   ],
   "source": [
    "# Fill NoData gaps in the Digital Surface Model (DSM)\n",
    "# Uses the same IDW interpolation method as DTM\n",
    "print(\"Filling gaps in DSM using IDW interpolation...\")\n",
    "result_dsm = lp.fill_nodata('dsm_temp.tif', shapefile_path)\n",
    "print(f\"âœ“ {result_dsm}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1b10935f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading meadow boundary and reprojecting to EPSG:6339...\n",
      "âœ“ Boundary loaded with 1 feature(s)\n"
     ]
    }
   ],
   "source": [
    "# Load meadow boundary and reproject to match raster coordinate system\n",
    "# EPSG:6339 = NAD83(2011) / Colorado Central (commonly used for Colorado LiDAR)\n",
    "print(\"Loading meadow boundary and reprojecting to EPSG:6339...\")\n",
    "gdf = gpd.read_file(shapefile_path)\n",
    "gdf = gdf.to_crs(6339)\n",
    "print(f\"âœ“ Boundary loaded with {len(gdf)} feature(s)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7104063a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clipping DTM to meadow boundary...\n",
      "âœ“ Saved as: dtm_clipped.tif\n"
     ]
    }
   ],
   "source": [
    "# Clip the filled DTM to the exact meadow boundary\n",
    "# This creates the final DTM product: dtm_clipped.tif\n",
    "print(\"Clipping DTM to meadow boundary...\")\n",
    "result_dtm_clip = lp.clip_and_rename_raster('dtm_temp_filled.tif', gdf)\n",
    "print(f\"âœ“ {result_dtm_clip}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "efd3619b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clipping DSM to meadow boundary...\n",
      "âœ“ Saved as: dsm_clipped.tif\n"
     ]
    }
   ],
   "source": [
    "# Clip the filled DSM to the exact meadow boundary  \n",
    "# This creates the final DSM product: dsm_clipped.tif\n",
    "print(\"Clipping DSM to meadow boundary...\")\n",
    "result_dsm_clip = lp.clip_and_rename_raster('dsm_temp_filled.tif', gdf)\n",
    "print(f\"âœ“ {result_dsm_clip}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dc7d1a01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Canopy Height Model (CHM)...\n",
      "âœ“ Saved as: chm_clipped.tif\n",
      "CHM represents vegetation height above ground surface\n"
     ]
    }
   ],
   "source": [
    "# Generate Canopy Height Model (CHM) by subtracting DTM from DSM\n",
    "# CHM = DSM - DTM (vegetation height above ground)\n",
    "# Negative values are set to 0 (below-ground artifacts)\n",
    "print(\"Generating Canopy Height Model (CHM)...\")\n",
    "result_chm = lp.chm('dsm_clipped.tif', 'dtm_clipped.tif', gdf)\n",
    "print(f\"âœ“ {result_chm}\")\n",
    "print(\"CHM represents vegetation height above ground surface\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f52898f",
   "metadata": {},
   "source": [
    "## File Cleanup and Naming\n",
    "Remove temporary files and rename final products with the meadow name for easy identification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05832053",
   "metadata": {},
   "source": [
    "## Processing Summary\n",
    "Complete the workflow and return to the parent directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "662c6671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scanning for TIFF files to clean up...\n",
      "Found 7 TIFF files\n"
     ]
    }
   ],
   "source": [
    "# Get list of all TIFF files in the working directory\n",
    "import glob\n",
    "\n",
    "print(\"Scanning for TIFF files to clean up...\")\n",
    "tif_files = glob.glob(os.path.join(os.getcwd(), \"*.tif\"))\n",
    "print(f\"Found {len(tif_files)} TIFF files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0ee12aee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning up temporary files and renaming final products...\n",
      "  Deleted: dsm_temp.tif\n",
      "  Renamed: dtm_clipped.tif â†’ dtm_Lacey.tif\n",
      "  Renamed: dsm_clipped.tif â†’ dsm_Lacey.tif\n",
      "  Deleted: dtm_temp_filled.tif\n",
      "  Deleted: dsm_temp_filled.tif\n",
      "  Renamed: chm_clipped.tif â†’ chm_Lacey.tif\n",
      "  Deleted: dtm_temp.tif\n",
      "\n",
      "âœ“ Cleanup complete: 4 files deleted, 3 files renamed\n"
     ]
    }
   ],
   "source": [
    "# Clean up temporary files and rename final products\n",
    "print(\"Cleaning up temporary files and renaming final products...\")\n",
    "\n",
    "files_deleted = 0\n",
    "files_renamed = 0\n",
    "\n",
    "for file_path in tif_files:\n",
    "    filename = os.path.basename(file_path)\n",
    "\n",
    "    # Delete temporary/intermediate files (keep only _clipped.tif files)\n",
    "    if \"_clipped.tif\" not in filename:\n",
    "        os.remove(file_path)\n",
    "        print(f\"  Deleted: {filename}\")\n",
    "        files_deleted += 1\n",
    "        continue\n",
    "\n",
    "    # Rename final products to include meadow name\n",
    "    # e.g., \"dtm_clipped.tif\" becomes \"dtm_Lacey.tif\"\n",
    "    if filename.endswith(\"_clipped.tif\"):\n",
    "        new_filename = filename.replace(\"_clipped.tif\", f\"_{name}.tif\")\n",
    "        new_path = os.path.join(os.getcwd(), new_filename)\n",
    "        os.rename(file_path, new_path)\n",
    "        print(f\"  Renamed: {filename} â†’ {new_filename}\")\n",
    "        files_renamed += 1\n",
    "\n",
    "print(f\"\\nâœ“ Cleanup complete: {files_deleted} files deleted, {files_renamed} files renamed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f6c6f8c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Returned to: /media/grendel/7db216a7-836f-4e8d-b439-e4f999cedb23/USGS/meadow_assessment\n",
      "\n",
      "ðŸŽ‰ LiDAR processing completed successfully!\n",
      "Final products saved to: /media/grendel/7db216a7-836f-4e8d-b439-e4f999cedb23/USGS/meadow_assessment/data/Lacey\n",
      "\n",
      "Generated files:\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'exists'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m product \u001b[38;5;129;01min\u001b[39;00m final_products:\n\u001b[32m     18\u001b[39m     product_path = product\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mproduct_path\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexists\u001b[49m():\n\u001b[32m     20\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  âœ“ \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mproduct\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     21\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mAttributeError\u001b[39m: 'str' object has no attribute 'exists'"
     ]
    }
   ],
   "source": [
    "# Return to the parent directory (notebooks folder)\n",
    "os.chdir(\"..\")\n",
    "current_dir = os.getcwd()\n",
    "print(f\"âœ“ Returned to: {current_dir}\")\n",
    "\n",
    "# Summarize the final products created\n",
    "output_dir = Path(f\"data/{name}\")\n",
    "final_products = [\n",
    "    f\"dtm_{name}.tif\",      # Digital Terrain Model (bare earth)\n",
    "    f\"dsm_{name}.tif\",      # Digital Surface Model (first surface)  \n",
    "    f\"chm_{name}.tif\"       # Canopy Height Model (vegetation height)\n",
    "]\n",
    "\n",
    "print(f\"\\nðŸŽ‰ LiDAR processing completed successfully!\")\n",
    "print(f\"Final products saved to: {output_dir.absolute()}\")\n",
    "print(\"\\nGenerated files:\")\n",
    "for product in final_products:\n",
    "    product_path = product\n",
    "    if product_path.exists():\n",
    "        print(f\"  âœ“ {product}\")\n",
    "    else:\n",
    "        print(f\"  âœ— {product} (not found)\")\n",
    "        \n",
    "print(f\"\\nThese files can now be used for meadow assessment and stream analysis.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215dd2f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
